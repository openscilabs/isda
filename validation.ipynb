{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "colab_type": "text",
                "id": "view-in-github"
            },
            "source": [
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openscilabs/isda/blob/main/validation.ipynb)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ISDA - Independent Structural-Dimensionality Analysis\n",
                "\n",
                "This notebook serves as a comprehensive validation suite for the Independent Structural-Dimensionality Analysis (ISDA) framework.\n",
                "It systematically evaluates the algorithm's efficacy across a spectrum of synthetic benchmarks, ranging from canonical correlation patterns\u2014including linear redundancies and latent manifolds\u2014to complex Multi-Objective Problems (MOPs). The analysis verifies ISDA's capability to correctly identify intrinsic dimensionality and preserve the topological fidelity of the Pareto frontier."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install ISDA \n",
                "!pip install --upgrade git+https://github.com/openscilabs/isda.git\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import isda\n",
                "\n",
                "# Reload for development iteration\n",
                "import importlib\n",
                "importlib.reload(isda)\n",
                "\n",
                "print(\"ISDA imported successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Generators & Utilities"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### General Helpers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def _truth(name, intrinsic_dim_expected, blocks_expected, notes=\"\"):\n",
                "    return {\n",
                "        \"name\": name,\n",
                "        \"intrinsic_dim_expected\": int(intrinsic_dim_expected),\n",
                "        \"blocks_expected\": blocks_expected,\n",
                "        \"notes\": notes,\n",
                "    }\n",
                "\n",
                "def _mk_block_names(start, size):\n",
                "    # start is 1-based\n",
                "    return [f\"f{i}\" for i in range(start, start + size)]\n",
                "\n",
                "def _repeat_with_small_noise(base, rng, noise):\n",
                "    # base: (N,) -> returns perturbed (N,)\n",
                "    return base + noise * rng.normal(size=base.shape[0])\n",
                "\n",
                "def _mop_df(Y):\n",
                "    return pd.DataFrame(Y, columns=[f\"f{i+1}\" for i in range(Y.shape[1])])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Validation Utilities\n",
                "Custom function to evaluate reconstruction fidelity on benchmark datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_reduced_model_fidelity(results_dict):\n",
                "    \"\"\"\n",
                "    Evaluates reconstruction fidelity and summarizes ISDA performance.\n",
                "    Adapted for local notebook usage.\n",
                "    \"\"\"\n",
                "    results_summary = []\n",
                "    for name, data in results_dict.items():\n",
                "        # data is now a dictionary wrapping an ISDAResult object and truth\n",
                "        result_obj = data.get(\"result_obj\")\n",
                "        truth = data.get(\"truth\", {})\n",
                "        \n",
                "        Y = result_obj.Y\n",
                "        mis = result_obj.best_mis\n",
                "        mis_indices = mis[\"mis_indices\"] if mis else []\n",
                "        \n",
                "        # Calculate fidelity (F_real)\n",
                "        if not mis_indices:\n",
                "            fidelity = 0.0\n",
                "            ses = 0.0\n",
                "        else:\n",
                "            # Use stored SES results if available, else recalculate\n",
                "            if result_obj.ses_results:\n",
                "                fidelity = result_obj.ses_results[\"F_real\"]\n",
                "                ses = result_obj.ses_results.get(\"ses\", 0.0)\n",
                "            else:\n",
                "                ses_out = isda.calculate_ses(Y, mis_indices, n_perm=1, return_details=True)\n",
                "                fidelity = ses_out[\"F_real\"]\n",
                "                ses = ses_out.get(\"ses\", 0.0)\n",
                "\n",
                "        expected_dim = truth.get(\"intrinsic_dim_expected\", None)\n",
                "        mis_size = len(mis_indices)\n",
                "        \n",
                "        # Metrics from ISDA result\n",
                "        regime_name = result_obj.regime.name if result_obj.regime else \"N/A\"\n",
                "        alpha_min = result_obj.alpha_min\n",
                "        alpha_max = result_obj.alpha_max\n",
                "        compactness = getattr(result_obj, \"min_compactness\", 1.0)\n",
                "\n",
                "        # Status heuristic\n",
                "        status = \"Bad\"\n",
                "        # If F_real is high, it's good\n",
                "        if fidelity >= 0.9:\n",
                "            status = \"OK\"\n",
                "        # If dimensionality matches exactly (even if Fidelity is tricky e.g. noise)\n",
                "        elif expected_dim and mis_size == expected_dim:\n",
                "            status = \"OK\"\n",
                "        # If strictly noise\n",
                "        elif str(regime_name) == \"SIGNAL_BELOW_NOISE\":\n",
                "            status = \"Noise\"\n",
                "\n",
                "        entry = {\n",
                "            \"Case\": name,\n",
                "            \"Alpha Min\": f\"{alpha_min:.2e}\",\n",
                "            \"Alpha Max\": f\"{alpha_max:.2e}\",\n",
                "            \"Regime\": regime_name,\n",
                "            \"Expected Dim\": expected_dim,\n",
                "            \"MIS Size\": mis_size,\n",
                "            \"Fidelity (F_real)\": f\"{fidelity:.4f}\",\n",
                "            \"SES\": f\"{ses:.4f}\",\n",
                "            \"Min Compactness\": f\"{compactness:.4f}\",\n",
                "            \"Status\": status\n",
                "        }\n",
                "        results_summary.append(entry)\n",
                "\n",
                "    df_summary = pd.DataFrame(results_summary)\n",
                "    \n",
                "    # Reorder columns\n",
                "    cols = [\n",
                "        \"Case\", \"Regime\", \"Alpha Min\", \"Alpha Max\", \"Expected Dim\", \n",
                "        \"MIS Size\", \"Fidelity (F_real)\", \"SES\", \"Min Compactness\", \"Status\"\n",
                "    ]\n",
                "    # Filter only columns that exist\n",
                "    df_summary = df_summary[cols]\n",
                "\n",
                "    return df_summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Canonical Structure Test Suite (qualitative calibration)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_cases(cases_list, N=300):\n",
                "    results = {}\n",
                "    for name, gen in cases_list:\n",
                "        print(f\"\\n{'='*80}\")\n",
                "        print(f\"Running {name}...\")\n",
                "        print(f\"{'='*80}\")\n",
                "        Y, truth = gen(N=N)\n",
                "        # Execute ISDA analysis (using defaults: caution=0.5)\n",
                "        result = isda.analyze(Y, caution=0.5, run_ses=True, name=name)\n",
                "        \n",
                "        # --- 1. Print Standard Summary & Diagnosis ---\n",
                "        print(result.summary())\n",
                "        \n",
                "        # --- 2. Print Detailed Structure (Clusters & Components) ---\n",
                "        isda_res = result.isda_results\n",
                "        comps = isda_res.get(\"components_labels\", [])\n",
                "        print(f\"\\n--- Identified Clusters (Connected Components: {len(comps)}) ---\")\n",
                "        for i, c in enumerate(comps):\n",
                "            print(f\"  C{i+1} : {c}\")\n",
                "\n",
                "        # --- 3. Print Ranked MIS Details ---\n",
                "        print(\"\\n--- Ranked Maximal Independent Sets (MIS) ---\")\n",
                "        mis_ranked = isda_res.get(\"mis_ranked\", [])\n",
                "        if not mis_ranked:\n",
                "            print(\"  None found.\")\n",
                "        else:\n",
                "            # Top 5 of Rank 1\n",
                "            rank1 = [m for m in mis_ranked if m.get(\"rank\") == 1]\n",
                "            print(f\"  Rank 1 (Best fit) - Total: {len(rank1)}\")\n",
                "            for i, m in enumerate(rank1[:5]):\n",
                "                print(f\"    #{i+1}: {m['mis_labels']} (Size: {len(m['mis_labels'])})\")\n",
                "            if len(rank1) > 5:\n",
                "                print(f\"    ... (+ {len(rank1)-5} more candidates)\")\n",
                "            \n",
                "            # One example of each subsequent rank\n",
                "            seen_ranks = {1}\n",
                "            for m in mis_ranked:\n",
                "                r = m.get(\"rank\")\n",
                "                if r not in seen_ranks:\n",
                "                    seen_ranks.add(r)\n",
                "                    print(f\"  Rank {r} Example:\")\n",
                "                    print(f\"    {m['mis_labels']} (Size: {len(m['mis_labels'])})\")\n",
                "\n",
                "        # --- 4. Plot Graph ---\n",
                "        try:\n",
                "            result.plot()\n",
                "            plt.show()\n",
                "        except Exception as e:\n",
                "            print(f\"Plotting failed: {e}\")\n",
                "        \n",
                "        results[name] = {\n",
                "            \"result_obj\": result,\n",
                "            \"truth\": truth\n",
                "        }\n",
                "    return results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# --- Battery 1: Standard Correlation Cases ---\n",
                "\n",
                "def make_case1_independence(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    Y = rng.normal(size=(N, M))\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    truth = _truth(\n",
                "        name=\"Case 1 - Total independence\",\n",
                "        intrinsic_dim_expected=M,\n",
                "        blocks_expected=[[c] for c in cols],\n",
                "        notes=\"Each objective is independent (Gaussian noise).\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case2_total_redundancy(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    latent = rng.normal(size=(N, 1))\n",
                "    noise = rng.normal(scale=0.05, size=(N, M))\n",
                "    Y = latent + noise\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    truth = _truth(\n",
                "        name=\"Case 2 - Total redundancy\",\n",
                "        intrinsic_dim_expected=1,\n",
                "        blocks_expected=[cols],\n",
                "        notes=\"A single latent; all objectives are noisy copies.\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case3_block_structure(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    assert M == 20\n",
                "    latent_blocks = rng.normal(size=(N, 4))\n",
                "    Y = np.zeros((N, M))\n",
                "    for b in range(4):\n",
                "        for j in range(5):\n",
                "            idx = 5*b + j\n",
                "            Y[:, idx] = latent_blocks[:, b] + rng.normal(scale=0.2, size=N)\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    blocks = [\n",
                "        [f\"f{i}\" for i in range(1, 6)],\n",
                "        [f\"f{i}\" for i in range(6, 11)],\n",
                "        [f\"f{i}\" for i in range(11, 16)],\n",
                "        [f\"f{i}\" for i in range(16, 21)],\n",
                "    ]\n",
                "    truth = _truth(\n",
                "        name=\"Case 3 - Blocks (4 x 5)\",\n",
                "        intrinsic_dim_expected=4,\n",
                "        blocks_expected=blocks,\n",
                "        notes=\"4 independent latents; each generates 5 objectives.\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case4_two_big_blocks(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    assert M == 20\n",
                "    latent_blocks = rng.normal(size=(N, 2))\n",
                "    Y = np.zeros((N, M))\n",
                "    for i in range(10):\n",
                "        Y[:, i] = latent_blocks[:, 0] + rng.normal(scale=0.2, size=N)\n",
                "    for i in range(10, 20):\n",
                "        Y[:, i] = latent_blocks[:, 1] + rng.normal(scale=0.2, size=N)\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    truth = _truth(\n",
                "        name=\"Case 4 - Blocks (2 x 10)\",\n",
                "        intrinsic_dim_expected=2,\n",
                "        blocks_expected=[\n",
                "            [f\"f{i}\" for i in range(1, 11)],\n",
                "            [f\"f{i}\" for i in range(11, 21)],\n",
                "        ],\n",
                "        notes=\"2 independent latents; each generates 10 objectives.\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case5_chain_structure(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    Y = np.zeros((N, M))\n",
                "    Y[:, 0] = rng.normal(size=N)\n",
                "    for j in range(1, M):\n",
                "        Y[:, j] = Y[:, j-1] + rng.normal(scale=0.2, size=N)\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    truth = _truth(\n",
                "        name=\"Case 5 - Chain\",\n",
                "        intrinsic_dim_expected=M,\n",
                "        blocks_expected=[cols],\n",
                "        notes=\"Sequential dependency.\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case6_mixed_structure(N=1000, M=20, seed=123):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    assert M == 20\n",
                "    Y = np.zeros((N, M))\n",
                "    # First 10: independent\n",
                "    Y[:, :10] = rng.normal(size=(N, 10))\n",
                "    # Last 10: two latents\n",
                "    latent1 = rng.normal(size=N)\n",
                "    latent2 = rng.normal(size=N)\n",
                "    for j in range(10, 15):\n",
                "        Y[:, j] = latent1 + rng.normal(scale=0.2, size=N)\n",
                "    for j in range(15, 20):\n",
                "        Y[:, j] = latent2 + rng.normal(scale=0.2, size=N)\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    df = pd.DataFrame(Y, columns=cols)\n",
                "    truth = _truth(\n",
                "        name=\"Case 6 - Mixed (indep + latents)\",\n",
                "        intrinsic_dim_expected=12,\n",
                "        blocks_expected=[[f\"f{i}\"] for i in range(1, 11)] + [[f\"f{i}\" for i in range(11, 16)], [f\"f{i}\" for i in range(16, 21)]],\n",
                "        notes=\"f1..f10 independent; f11..f15 latent1; f16..f20 latent2.\"\n",
                "    )\n",
                "    return df, truth\n",
                "\n",
                "def make_case7_pure_conflict_groups(N=1000, M=20, noise=0.05, seed=123, **kwargs):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    if M < 2:\n",
                "        raise ValueError(\"M must be >= 2\")\n",
                "    M_pos = (M + 1) // 2\n",
                "    M_neg = M - M_pos\n",
                "    x = rng.normal(size=N)\n",
                "    Y_pos = np.column_stack([x + noise * rng.normal(size=N) for _ in range(M_pos)])\n",
                "    Y_neg = np.column_stack([(-x) + noise * rng.normal(size=N) for _ in range(M_neg)])\n",
                "    Y = np.column_stack([Y_pos, Y_neg])\n",
                "    cols = [f\"f{i+1}\" for i in range(M)]\n",
                "    Y = pd.DataFrame(Y, columns=cols)\n",
                "    truth = {\n",
                "        \"name\": f\"Case 7 - Structural conflict (anti-corr) 2-groups\",\n",
                "        \"intrinsic_dim_expected\": 2,\n",
                "        \"blocks_expected\": [cols[:M_pos], cols[M_pos:]],\n",
                "        \"notes\": \"Conflict groups (+x and -x).\",\n",
                "    }\n",
                "    return Y, truth\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Synthetic MOP Test Suite (nferential validation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Battery 2: MOP Benchmarks ---\n",
                "\n",
                "def mopA_monotonic_redundancy(N=1000, seed=123, noise=0.0):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    x = rng.uniform(0.0, 1.0, size=N)\n",
                "\n",
                "    # 20 monotonic transformations (all 1D redundant)\n",
                "    feats = [\n",
                "        x,\n",
                "        2.0 * x + 0.1,\n",
                "        np.log(1.0 + 9.0 * x),\n",
                "        x**2,\n",
                "        np.sqrt(np.maximum(x, 0.0)),\n",
                "        x**3,\n",
                "        np.exp(0.5 * x) - 1.0,\n",
                "        1.0 / (1.0 + np.exp(-10.0 * (x - 0.5))),\n",
                "        (x + 0.2) ** 2,\n",
                "        np.log(1.0 + 3.0 * x),\n",
                "        np.tanh(2.0 * x),\n",
                "        (1.0 + x) ** 1.5,\n",
                "        np.clip(x + 0.05, 0, 1),\n",
                "        np.clip(1.2 * x, 0, 1),\n",
                "        np.log1p(20.0 * x) / np.log1p(20.0),\n",
                "        (x + 1e-6) ** 0.25,\n",
                "        (x + 0.1) ** 3,\n",
                "        np.sqrt(np.maximum(0.1 + x, 0.0)),\n",
                "        np.exp(x) - 1.0,\n",
                "        (x + 0.3) ** 2,\n",
                "    ]\n",
                "    Y = np.vstack([_repeat_with_small_noise(f, rng, noise) for f in feats]).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-A \u2014 Monotonic redundancy (1D, M=20)\",\n",
                "        intrinsic_dim_expected=1,\n",
                "        blocks_expected=[_mk_block_names(1, 20)],\n",
                "        notes=\"20 objectives as monotonic (and redundant) transformations of the same latent x.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "def mopB_tradeoff_with_redundancies(N=1000, seed=123, noise=0.02):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    a = rng.uniform(0.0, 1.0, size=N)\n",
                "    b = rng.uniform(0.0, 1.0, size=N)\n",
                "\n",
                "    # Plausible latents\n",
                "    C = 0.6 * a + 0.8 * b            # cost in ~[0,1.4]\n",
                "    E = b + 0.3 * (1.0 - a)          # consumption in ~[0,1.3]\n",
                "    P = a * (1.0 - b) + 0.2 * a      # performance can go up to 1.2 -> BUG for Q\n",
                "\n",
                "    # FIX: force performance to stay in [0,1] so that Q=1-P stays in [0,1]\n",
                "    P = np.clip(P, 0.0, 1.0)\n",
                "    Q = 1.0 - P\n",
                "\n",
                "    # 7 \"cost\" objectives\n",
                "    cost_feats = [\n",
                "        C,\n",
                "        _repeat_with_small_noise(C, rng, noise),\n",
                "        1.0 + 2.0 * C,\n",
                "        np.log1p(9.0 * C),\n",
                "        np.sqrt(np.maximum(C, 0.0)),\n",
                "        C**2,\n",
                "        (C + 0.1) ** 1.5,\n",
                "    ]\n",
                "\n",
                "    # 7 \"consumption\" objectives\n",
                "    cons_feats = [\n",
                "        E,\n",
                "        _repeat_with_small_noise(E, rng, noise),\n",
                "        np.sqrt(np.maximum(E, 0.0)),\n",
                "        np.log1p(9.0 * E),\n",
                "        E**2,\n",
                "        (E + 0.05),\n",
                "        (E + 0.2) ** 1.3,\n",
                "    ]\n",
                "\n",
                "    # 6 \"performance\" objectives (minimization via 1-P), with protected domain\n",
                "    Q_rep = np.clip(_repeat_with_small_noise(Q, rng, noise), 0.0, 1.0)\n",
                "\n",
                "    perf_feats = [\n",
                "        Q,\n",
                "        Q_rep,\n",
                "        Q**2,\n",
                "        np.sqrt(np.maximum(Q, 0.0)),\n",
                "        np.log1p(9.0 * Q),            # now Q \u2208 [0,1] -> always valid\n",
                "        (Q + 0.1) ** 1.2,             # now Q+0.1 \u2208 [0.1,1.1] -> always valid\n",
                "    ]\n",
                "\n",
                "    feats = cost_feats + cons_feats + perf_feats\n",
                "    Y = np.vstack(feats).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-B \u2014 Trade-off + redundancies (~2D, M=20)\",\n",
                "        intrinsic_dim_expected=2,\n",
                "        blocks_expected=[_mk_block_names(1, 7), _mk_block_names(8, 7), _mk_block_names(15, 6)],\n",
                "        notes=\"Three families (cost/consumption/performance) with internal redundancies; effective tends to ~2.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "def mopC_latent_blocks_4x5(N=1000, seed=123, noise=0.02):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    u, v, w, z = rng.uniform(0.0, 1.0, size=(4, N))\n",
                "    eps = rng.normal(size=N)\n",
                "\n",
                "    b1 = [u, 2*u, u**2, np.sqrt(np.maximum(u,0.0)), np.log1p(9*u)]\n",
                "    b2 = [v, v+0.5, np.log1p(9*v), v**2, np.sqrt(np.maximum(v,0.0))]\n",
                "    b3 = [w, w+noise*eps, np.sqrt(np.maximum(w,0.0)), np.log1p(9*w), (w+0.1)**2]\n",
                "    b4 = [z, (1.0+z)**2, np.exp(z)-1.0, np.log1p(9*z), np.sqrt(np.maximum(z,0.0))]\n",
                "\n",
                "    feats = b1 + b2 + b3 + b4\n",
                "    Y = np.vstack(feats).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-C \u2014 Latent blocks (4\u00d75, M=20)\",\n",
                "        intrinsic_dim_expected=4,\n",
                "        blocks_expected=[_mk_block_names(1,5), _mk_block_names(6,5), _mk_block_names(11,5), _mk_block_names(16,5)],\n",
                "        notes=\"Four independent factors; each block (5 objectives) is internally redundant.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "def mopD_pure_conflict_groups(N=1000, seed=123, noise=0.0):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    x = rng.uniform(0.0, 1.0, size=N)\n",
                "\n",
                "    g1 = [\n",
                "        x,\n",
                "        2*x + 0.1,\n",
                "        np.log1p(9*x),\n",
                "        x**2,\n",
                "        np.sqrt(np.maximum(x,0.0)),\n",
                "        x**3,\n",
                "        np.tanh(2*x),\n",
                "        np.log1p(3*x),\n",
                "        (x+0.2)**2,\n",
                "        (1.0 + x)**1.5,\n",
                "    ]\n",
                "    y = 1.0 - x\n",
                "    g2 = [\n",
                "        y,\n",
                "        2*y + 0.1,\n",
                "        np.log1p(9*y),\n",
                "        y**2,\n",
                "        np.sqrt(np.maximum(y,0.0)),\n",
                "        y**3,\n",
                "        np.tanh(2*y),\n",
                "        np.log1p(3*y),\n",
                "        (y+0.2)**2,\n",
                "        (1.0 + y)**1.5,\n",
                "    ]\n",
                "\n",
                "    feats = [_repeat_with_small_noise(f, rng, noise) for f in (g1 + g2)]\n",
                "    Y = np.vstack(feats).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-D \u2014 Structural conflict (anti-corr) 2-groups (M=20)\",\n",
                "        intrinsic_dim_expected=2,\n",
                "        blocks_expected=[_mk_block_names(1,10), _mk_block_names(11,10)],\n",
                "        notes=\"Two internally redundant groups (+x and 1-x), but antagonistic to each other: conflict must be preserved.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "def mopE_partial_redundancy_noisy(N=1000, seed=123, noise=0.05):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    a = rng.uniform(0.0, 1.0, size=N)\n",
                "    b = rng.uniform(0.0, 1.0, size=N)\n",
                "    eps = rng.normal(size=N)\n",
                "\n",
                "    # subfamily A: redundant around 'a' (10)\n",
                "    A = [\n",
                "        a,\n",
                "        a + noise*eps,\n",
                "        a - noise*eps,\n",
                "        2*a + 0.1,\n",
                "        a**2,\n",
                "        np.sqrt(np.maximum(a,0.0)),\n",
                "        np.log1p(9*a),\n",
                "        (a+0.2)**2,\n",
                "        np.tanh(2*a),\n",
                "        (1.0+a)**1.2,\n",
                "    ]\n",
                "\n",
                "    # subfamily B: \"b\" (4)\n",
                "    B = [\n",
                "        b,\n",
                "        b + 0.5,\n",
                "        np.sqrt(np.maximum(b,0.0)),\n",
                "        np.log1p(9*b),\n",
                "    ]\n",
                "\n",
                "    # mixtures/compounds: functions of s=a+b (6)\n",
                "    s = a + b\n",
                "    C = [\n",
                "        s,\n",
                "        s**2,\n",
                "        np.sqrt(np.maximum(s,0.0)),\n",
                "        np.log1p(9*s),\n",
                "        (s+0.1)**1.5,\n",
                "        1.0/(1.0+np.exp(-10*(s-1.0))),\n",
                "    ]\n",
                "\n",
                "    feats = A + B + C\n",
                "    Y = np.vstack(feats).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-E \u2014 Partial redundancy + noise (M=20)\",\n",
                "        intrinsic_dim_expected=2,\n",
                "        blocks_expected=[_mk_block_names(1,10), _mk_block_names(11,4), _mk_block_names(15,6)],\n",
                "        notes=\"Trio/quartet of 'a' extended to 10 redundants; 'b' (4); and 6 compounds around s=a+b.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "def mopF_regime_switching(N=1000, seed=123, sharpness=20.0, noise=0.0):\n",
                "    rng = np.random.default_rng(seed)\n",
                "    a = rng.uniform(0.0, 1.0, size=N)\n",
                "    b = rng.uniform(0.0, 1.0, size=N)\n",
                "\n",
                "    s = 1.0 / (1.0 + np.exp(-sharpness * (a - 0.5)))\n",
                "    L = (1.0 - s) * a + s * b\n",
                "\n",
                "    eps = rng.normal(size=N)\n",
                "\n",
                "    L_feats = [\n",
                "        L,\n",
                "        L**2,\n",
                "        np.log1p(9*L),\n",
                "        np.sqrt(np.maximum(L,0.0)),\n",
                "        (L+0.1)**1.5,\n",
                "        np.tanh(2*L),\n",
                "        np.exp(0.5*L)-1.0,\n",
                "        (L+0.2)**2,\n",
                "        np.log1p(3*L),\n",
                "        _repeat_with_small_noise(L, rng, 0.02) if noise == 0.0 else _repeat_with_small_noise(L, rng, noise),\n",
                "    ]\n",
                "\n",
                "    b_feats = [\n",
                "        b,\n",
                "        np.sqrt(np.maximum(b,0.0)),\n",
                "        np.log1p(9*b),\n",
                "        b**2,\n",
                "        (b+0.1)**1.5,\n",
                "        np.tanh(2*b),\n",
                "        np.exp(0.5*b)-1.0,\n",
                "        (b+0.2)**2,\n",
                "        np.log1p(3*b),\n",
                "        _repeat_with_small_noise(b, rng, 0.02) if noise == 0.0 else _repeat_with_small_noise(b, rng, noise),\n",
                "    ]\n",
                "\n",
                "    feats = L_feats + b_feats\n",
                "    Y = np.vstack(feats).T\n",
                "\n",
                "    truth = _truth(\n",
                "        name=\"MOP-F \u2014 Regimes (mixture, M=20)\",\n",
                "        intrinsic_dim_expected=2,\n",
                "        blocks_expected=[_mk_block_names(1,10), _mk_block_names(11,10)],\n",
                "        notes=\"10 objectives redundant around L (mixture by regime) + 10 redundant around b; global correlation can be misleading.\"\n",
                "    )\n",
                "    return _mop_df(Y), truth\n",
                "\n",
                "battery1 = [\n",
                "    (\"Case 1 - Total independence\", make_case1_independence),\n",
                "    (\"Case 2 - Total redundancy\", make_case2_total_redundancy),\n",
                "    (\"Case 3 - Blocks (4 x 5)\", make_case3_block_structure),\n",
                "    (\"Case 4 - Blocks (2 x 10)\", make_case4_two_big_blocks),\n",
                "    (\"Case 5 - Chain\", make_case5_chain_structure),\n",
                "    (\"Case 6 - Mixed (indep + latents)\", make_case6_mixed_structure),\n",
                "    (\"Case 7 - Structural conflict (anti-corr) with groups\", make_case7_pure_conflict_groups),\n",
                "]\n",
                "\n",
                "battery2 = [\n",
                "    (\"MOP-A \u2014 Monotonic redundancy\", mopA_monotonic_redundancy),\n",
                "    (\"MOP-B \u2014 Trade-off + redundancies\", mopB_tradeoff_with_redundancies),\n",
                "    (\"MOP-C \u2014 Latent blocks\", mopC_latent_blocks_4x5),\n",
                "    (\"MOP-D \u2014 Pure conflict groups\", mopD_pure_conflict_groups),\n",
                "    (\"MOP-E \u2014 Partial redundancy + noise\", mopE_partial_redundancy_noisy),\n",
                "    (\"MOP-F \u2014 Regime switching\", mopF_regime_switching),\n",
                "]\n",
                "\n",
                "print(\"\\n=== RUNNING STANDARD CORRELATION BATTERY ===\")\n",
                "battery1_results = run_cases(battery1)\n",
                "\n",
                "battery1_fidelity_df = evaluate_reduced_model_fidelity(battery1_results)\n",
                "print(\"\\n--- ISDA Reconstruction Fidelity Evaluation for Canonical Cases ---\")\n",
                "print(battery1_fidelity_df.to_markdown(index=False))\n",
                "\n",
                "print(\"\\n\\n=== RUNNING MOP BENCHMARK BATTERY ===\")\n",
                "mop_results = run_cases(battery2)\n",
                "\n",
                "mop_fidelity_df = evaluate_reduced_model_fidelity(mop_results)\n",
                "print(\"\\n--- ISDA Reconstruction Fidelity Evaluation for MOP Cases ---\")\n",
                "print(mop_fidelity_df.to_markdown(index=False))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}